# -*- coding: utf-8 -*-
"""Herrera-Viedma_CRP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IcE8JudVPLn3gZ_IOfdxv6RmJJeGb9I8
"""

import numpy as np # type: ignore
import math
import matplotlib.pyplot as plt # type: ignore
from sklearn.decomposition import PCA # type: ignore
from sklearn.manifold import MDS # type: ignore


# Esta funcion solo crea las preferencias del ejemplo del paper para comprobar que los calculos son correctos.
def generar_matrices_ejemplo():

  matrices = np.zeros((9, 6, 6))

  # Introducir manualmente los valores en cada matriz
  matrices[0] = [
    [0.5, 0.4, 0.6, 0.9, 0.7, 0.8],
    [0.6, 0.5, 0.7, 1.0, 0.8, 0.9],
    [0.4, 0.3, 0.5, 0.8, 0.6, 0.7],
    [0.1, 0.0, 0.2, 0.5, 0.3, 0.4],
    [0.3, 0.2, 0.4, 0.7, 0.5, 0.6],
    [0.2, 0.1, 0.3, 0.6, 0.4, 0.5]
  ]

  matrices[1] = [
    [0.5, 0.7, 0.8, 0.6, 1.0, 0.9],
    [0.3, 0.5, 0.6, 0.4, 0.8, 0.7],
    [0.2, 0.4, 0.5, 0.3, 0.7, 0.6],
    [0.4, 0.6, 0.7, 0.5, 0.9, 0.8],
    [0.0, 0.2, 0.3, 0.1, 0.5, 0.4],
    [0.1, 0.3, 0.4, 0.2, 0.6, 0.5]
  ]

  matrices[2] = [
    [0.5, 0.69, 0.12, 0.2, 0.36, 0.9],
    [0.31, 0.5, 0.06, 0.1, 0.2, 0.8],
    [0.88, 0.94, 0.5, 0.64, 0.8, 0.98],
    [0.8, 0.9, 0.36, 0.5, 0.69, 0.97],
    [0.64, 0.8, 0.2, 0.31, 0.5, 0.94],
    [0.1, 0.2, 0.02, 0.03, 0.06, 0.5]
  ]

  matrices[3] = [
    [0.5, 0.1, 0.36, 0.69, 0.16, 0.26],
    [0.9, 0.5, 0.84, 0.95, 0.62, 0.76],
    [0.64, 0.16, 0.5, 0.8, 0.25, 0.39],
    [0.31, 0.05, 0.2, 0.5, 0.08, 0.14],
    [0.84, 0.38, 0.75, 0.92, 0.5, 0.66],
    [0.74, 0.24, 0.61, 0.86, 0.34, 0.5]
  ]

  matrices[4] = [
    [0.5, 0.55, 0.45, 0.25, 0.7, 0.3],
    [0.45, 0.5, 0.7, 0.85, 0.4, 0.8],
    [0.55, 0.3, 0.5, 0.65, 0.7, 0.6],
    [0.75, 0.15, 0.35, 0.5, 0.95, 0.6],
    [0.3, 0.6, 0.3, 0.05, 0.5, 0.85],
    [0.7, 0.2, 0.2, 0.4, 0.15, 0.5]
  ]

  matrices[5] = [
    [0.5, 0.7, 0.75, 0.95, 0.6, 0.85],
    [0.3, 0.5, 0.55, 0.8, 0.4, 0.65],
    [0.25, 0.45, 0.5, 0.7, 0.6, 0.45],
    [0.05, 0.2, 0.3, 0.5, 0.85, 0.4],
    [0.4, 0.6, 0.4, 0.15, 0.5, 0.75],
    [0.15, 0.35, 0.55, 0.6, 0.25, 0.5]
  ]

  matrices[6] = [
    [0.5, 0.34, 0.25, 0.82, 0.75, 0.87],
    [0.66, 0.5, 0.25, 0.18, 0.82, 0.91],
    [0.75, 0.75, 0.5, 0.94, 0.91, 1.0],
    [0.18, 0.82, 0.065, 0.5, 0.34, 0.75],
    [0.25, 0.18, 0.09, 0.66, 0.5, 0.82],
    [0.13, 0.09, 0.0, 0.25, 0.18, 0.5]
  ]

  matrices[7] = [
    [0.5, 0.13, 0.18, 0.34, 0.75, 0.09],
    [0.87, 0.5, 0.66, 0.82, 0.91, 0.25],
    [0.82, 0.34, 0.5, 0.75, 0.87, 0.82],
    [0.66, 0.18, 0.25, 0.5, 0.75, 0.91],
    [0.25, 0.09, 0.13, 0.25, 0.5, 0.97],
    [0.91, 0.75, 0.18, 0.09, 0.03, 0.5]
  ]

  return matrices

# Genera un vector de m matrices de tamaño n x n con valores aleatorios entre 0 y 1 que representan las opiniones de los expertos.
# :param m: Número de matrices.
# :param n: Tamaño de cada matriz (n x n).
# :return: Lista de m matrices numpy de tamaño n x n.
def generar_matrices(m, n):
    return [np.random.uniform(0, 1, (n, n)) for _ in range(m)]

# Calcula el cuantificador lingüístico difuso.
# :param r: Índice.
# :param a: Parámetro a del cuantificador lingüístico.
# :param b: Parámetro b del cuantificador lingüístico.
def Q(r, a, b):
    if r < a:
        return 0.0
    elif r > b:
        return 1.0
    else:
        return (r - a) / (b - a)

# Calcula los pesos OWA basados en los parámetros dados.
# :param n: Número de pesos a calcular.
# :param a: Parámetro a del cuantificador lingüístico.
# :param b: Parámetro b del cuantificador lingüístico.
# :return: Lista con los pesos OWA.
def calcular_pesos_OWA(m, lq):

    result = [0.0] * m
    q_values = {}

    for k in range(1, m + 1):
        r1 = k / m
        r2 = (k - 1) / m

        if r1 not in q_values:
            q_values[r1] = Q(r1, lq[0], lq[1])
        if r2 not in q_values:
            q_values[r2] = Q(r2, lq[0], lq[1])

        result[k - 1] = round(q_values[r1] - q_values[r2], 2)

    return result

# Aplica el operador OWA a una lista de valores usando los pesos dados.
# :param valores: Lista de valores a agregar.
# :param pesos: Lista de pesos OWA (debe tener la misma longitud que valores).
# :return: Valor agregado mediante OWA.
def owa(valores, pesos):
    valores_ordenados = sorted(valores, reverse=True)  # Ordenamos los valores en orden descendente
    return sum(v * w for v, w in zip(valores_ordenados, pesos))

# Calcula el valor agregado usando una variante del operador OWA OR-like.
# :param values: Lista de valores a agregar.
# :param beta: Parámetro de rigurosidad de consenso.
# :param Xsol: Conjunto de índices seleccionados.
# :return: Valor de agregación redondeado a 2 decimales.
def s_owa_or_like(values, beta, Xsol):
  size_1 = len(Xsol)
  size_2 = len(values) - size_1

  value_1 = sum(values[i] for i in Xsol) / size_1 if size_1 > 0 else 0.0
  value_2 = sum(values[i] for i in range(len(values)) if i not in Xsol) / size_2 if size_2 > 0 else 0.0

  return ((1 - beta) * value_1) + (beta * value_2)

# Agrega las opiniones de los expertos por criterio y después por alternativas mediante el operador OWA.
# :param pref: Preferencias de los expertos.
# :param n_exp: Número de expertos.
# :param n_alt: Número de alternativas.
# :param n_crit: Número de criterios.
# :param w_cri: Pesos asociados a los criterios.
# :param w_exp: Pesos asociados a los expertos.
# :return: Opinión colectiva de los expertos.
def calcular_colectiva_OWA(pref, n_exp, n_alt, n_crit, w_cri, w_exp):
  # Paso 1: Agregar todas las matrices de cada experto en una única matriz por experto
  agregacion_por_experto = np.zeros((n_exp, n_alt, n_alt))

  for exp in range(n_exp):
      for i in range(n_alt):
          for j in range(n_alt):
            valores = [pref[exp * n_crit + cr][i][j] for cr in range(n_crit)]
            agregacion_por_experto[exp][i][j] = owa(valores, w_cri)  # OWA sobre criterios

  # Paso 2: Agregar las matrices resultantes de cada experto en una única matriz final
  matriz_colectiva = np.zeros((n_alt, n_alt))

  for i in range(n_alt):
    for j in range(n_alt):
      valores = [agregacion_por_experto[exp][i][j] for exp in range(n_exp)]
      matriz_colectiva[i][j] = owa(valores, w_exp) # OWA sobre expertos

  return matriz_colectiva

# Calcula el QGDD aplicando el operador OWA sobre las preferencias de cada alternativa.
# :param n_alt: Número de alternativas.
# :param pref: Matriz de preferencias.
# :param w: Vector de pesos OWA.
# :param owa: Función que aplica el operador OWA.
# :return: Vector de valores QGDD para cada alternativa.
def calcular_QGDD(n_alt, pref, w):
  result = np.zeros(n_alt)

  for i in range(n_alt):
    values = np.array([pref[i][j] for j in range(n_alt)])  # Extraer la fila i
    result[i] = owa(values, w)  # Aplicar OWA a la fila

  return result

# Calcula la diferencia de posiciones entre un ranking de un experto y el ranking colectivo
# :param c_ranking: Lista con el ranking colectivo.
# :param e_ranking: Lista con el ranking de un experto.
# :return: Lista ordenada con las diferencias de posiciones.
def diferencia_ranking(c_ranking, e_ranking):
    # Crear diccionarios con las posiciones de cada alternativa en los rankings
    pos_colectivo = {alt: i for i, alt in enumerate(c_ranking)}
    pos_expert = {alt: i for i, alt in enumerate(e_ranking)}

    # Calcular la diferencia en orden de las alternativas del ranking colectivo
    differences = [pos_colectivo[alt] - pos_expert[alt] for alt in sorted(pos_colectivo.keys())]

    return differences

# Calcula las diferencias entre los rankings de los expertos y el ranking del grupo.
# :param alternatives_rankings: Lista de listas donde cada fila es un ranking.
# :return: Matriz de diferencias entre los rankings de los expertos y el ranking del grupo.
def calcular_diferencia_rankings(alternatives_rankings):
    n_exp = len(alternatives_rankings) - 1  # Última fila es el ranking del grupo
    n_alt = len(alternatives_rankings[0])

    result = np.zeros((n_exp, n_alt), dtype=int)  # Matriz de diferencias

    c_ranking = alternatives_rankings[-1]  # Última fila = ranking del grupo

    for i in range(n_exp):
        result[i] = diferencia_ranking(c_ranking, alternatives_rankings[i])

    return result

# Devuelve un conjunto con los índices donde el valor en ranking es 0 (primera posición).
# :param ranking: Ranking de las alterantivas.
# :return: Conjunto de índices donde ranking[i] == 0.
def conjunto_solucion(ranking):
  return {i for i, value in enumerate(ranking) if value == 0}

# Calcula los grados de consenso sobre alternativas para cada experto.
# :param differences_between_rankings: Matriz de diferencias entre rankings (n_exp x n_alt).
# :param b: Parámetro de rigurosidad de consenso.
# :return: Matriz de grados de consenso (n_exp x n_alt).
def calcular_consenso_exp_alt(differences_between_rankings, b):
    n_exp = len(differences_between_rankings)
    n_alt = len(differences_between_rankings[0])

    result = np.zeros((n_exp, n_alt), dtype=float)

    for e in range(n_exp):
        for a in range(n_alt):
            result[e][a] = round((abs(differences_between_rankings[e][a]) / (n_alt - 1)) ** b, 2)

    return result

# Calcula los grados de consenso para cada alternativa a partir de los expertos.
# :param consensus_degrees_on_alternatives_by_experts: Matriz de grados de consenso (n_exp x n_alt).
# :return: Vector con los grados de consenso para cada alternativa.
def calcular_consenso_alt(consensus_degrees_exp_alt):
  result = np.zeros(n_alt, dtype=float)

  for a in range(n_alt):
    result[a] = sum(consensus_degrees_exp_alt[e][a] for e in range(n_exp)) / n_exp
    result[a] = round(1.0 - result[a], 2)  # Se invierte el valor y se redondea a 2 decimales

  return result

# Calcula la medida de proximidad aplicando la transformación 1 - value y luego OWA OR-like.
# :param proximity_measures_by_expert: Lista de valores de proximidad de cada experto.
#:param beta: Parámetro de ponderación.
#:param Xsol: Conjunto de índices seleccionados.
# :return: Medida de proximidad calculada.
def calcular_proximidad(proximity_measures_exp, beta, Xsol):
  aux = [1.0 - value for value in proximity_measures_exp]

  return s_owa_or_like(aux, beta, Xsol)

# Calcula las medidas de proximidad para cada experto.
# :param proximity_measures_by_experts: Matriz de proximidades (n_experts x n_alternatives).
# :param beta: Parámetro de ponderación.
# :param Xsol: Conjunto de índices seleccionados.
# :return: Lista con las medidas de proximidad calculadas para cada experto.
def calcular_medidas_proximidad(proximity_measures_exp, beta, Xsol):
  experts = len(proximity_measures_exp)

  return [calcular_proximidad(proximity_measures_exp[i], beta, Xsol) for i in range(experts)]

# Selecciona los expertos más alejado a la solución del grupo (la mitad menos cercana).
# :param proximity_measures: Lista con las medidas de proximidad de los expertos.
# :return: Conjunto de índices de los expertos con menor proximidad.
def expertos_mas_alejados(proximity_measures):
  ordered_values = sorted(proximity_measures)

  threshold = ordered_values[len(ordered_values) // 2]

  return {i for i, value in enumerate(proximity_measures) if value <= threshold}

# Determina los cambios en las preferencias de cada experto en función de las diferencias de ranking.
# :param farthest_experts: Conjunto de índices de los expertos más alejados de la opinión del grupo.
# :param differences_between_rankings: Matriz de diferencias entre rankings (n_exp x n_alt).
# :return: Diccionario donde las claves son los expertos y los valores son listas con los tipos de cambio.
def detectar_cambios(farthest_experts, differences_between_rankings):
  result = {}

  n_alt = len(differences_between_rankings[0])

  for exp in farthest_experts:
    changes = []
    for alt in range(n_alt):
      diff = differences_between_rankings[exp][alt]
      if diff < 0:
        changes.append(1) # Incrementar la preferencia.
      elif diff == 0:
        changes.append(0) # No modificar la preferencia.
      else:
        changes.append(-1) # Decrementar la preferencia.

    result[exp] = changes

  return result

# Genera una lista de cambios basada en una distribución binomial.
# :param number_of_changes: Número total de cambios a generar.
# :param prob_accept: Probabilidad de aceptar un cambio (valor entre 0 y 1).
# :param scale: Factor de escala para determinar la magnitud del cambio.
# :return: Lista con los valores de cambio aceptados o 0 si es rechazado.
def simular_comportamiento(number_of_changes, prob_accept, scale):

  # Simulación de aceptación/rechazo basada en una distribución binomial
  accept_changes = np.random.binomial(1, prob_accept, number_of_changes)

  # Generar valores de cambio aleatorios en un rango [-scale, scale]
  change_values = np.random.uniform(0, scale, number_of_changes)

  # Aplicar los cambios solo si fueron aceptados, si no, asignar 0
  final_changes = change_values * accept_changes

  return final_changes.tolist()

# Modifica las preferencias de los expertos en base a los cambios calculados.
# :param changes: Diccionario con la lista de cambios
# :param preferences: Matrices de preferencias de expertos.
def aplicar_cambios(changes, preferences):
    n_alt = len(preferences[0])

    # Contar cuántos cambios se deben hacer
    number_of_changes = sum(
        1 for changes_array in changes.values() for change in changes_array if change != 0
    )

    # Obtener el comportamiento de los expertos sobre los cambios. Esto permite simular si los expertos aceptan o rechazan los cambios. Con expertos reales no es necesario pero lo tendremos en cuenta para las simulaciones.
    changes_to_make = simular_comportamiento(number_of_changes, 1.0, 0.2)

    # Aplicar cambios
    number_of_changes = 0
    for expert_index, changes_array in changes.items():
      for i, change in enumerate(changes_array):
        if change != 0:
          value = changes_to_make[number_of_changes]
          number_of_changes += 1

          if value != 0.0:
            if change == -1:
              value *= -1.0  # Si el cambio es Decrease, el valor se hace negativo

            for j in range(n_alt):
              if i != j:
                new_value = preferences[expert_index][i][j]
                new_value += value

                # Asegurar que el nuevo valor esté en el rango [0,1]
                new_value = max(0.0, min(1.0, new_value))

                preferences[expert_index][i][j] = new_value # Nuevo valor para la preferencia


# Representa gráficamente las preferencias de los expertos usando PCA o MDS. Será una visualización que incluyamos en la ventana de análisis de resultados.
# :param preferences: Lista de matrices de preferencias (n_experts, n_alt, n_alt).
# :param collective_opinion: Matriz de preferencias colectiva (n_alt, n_alt).
# :param method: 'PCA' para Análisis de Componentes Principales, 'MDS' para Multi-Dimensional Scaling.
def visualizar_preferencias(preferences, n_round, method):

  n_experts = len(preferences) - 1  # Última posición es la opinión colectiva

  # Convertir matrices n_alt x n_alt en vectores 1D de tamaño (n_alt^2)
  preferences_flat = np.array([pref.flatten() for pref in preferences])

  # Aplicar PCA o MDS
  if method == 'PCA':
    reducer = PCA(n_components=2)
  else:
    reducer = MDS(n_components=2, dissimilarity='euclidean', random_state=42)

  transformed = reducer.fit_transform(preferences_flat)

  # Separar la opinión colectiva y los expertos en el espacio reducido
  collective_point = transformed[-1]  # Última posición es la colectiva
  expert_points = transformed[:-1] - collective_point  # Resto son los expertos)

  # Representar
  plt.figure(figsize=(6, 4))
  plt.scatter(expert_points[:, 0], expert_points[:, 1], color='blue', label="Expertos", alpha=0.7)
  plt.scatter(collective_point[0], collective_point[1], color='red', marker='o', s=50, label="Colectiva")

  # Etiquetas de los expertos
  for i, point in enumerate(expert_points):
    plt.text(point[0], point[1], f"Exp {i+1}", fontsize=9, ha='right', color='black')

  plt.xlabel("Componente 1")
  plt.ylabel("Componente 2")
  plt.title(n_round + f"({method})")
  plt.legend()
  plt.grid(True)
  plt.show()

# PARÁMETROS GENERALES

n_alt = 6 # Número de alternativas.
n_crit = 1 # Número de criterios.
n_exp = 8 # Número de expertos.

maxRounds = 15 # Rondas máximas del proceso de consenso.
cl = 0.85 # Umbral de consenso. Consenso a alcanzar por el grupo.

pref = generar_matrices_ejemplo() # Preferencias de los expertos.

# PARÁMETROS DEL MODELO DE CONSENSO HERRERA-VIEDMA

ag_lq = [0.3, 0.8] # Parámetros usados para la agregación de preferencias. Cuantificadores lingüísticos most(0.3,0.8), at least half(0,0.5), as many as possible(0.5,1).
ex_lq = [0.5, 1.0] # Parámetros usados para obtener el ranking. Cuantificadores lingüísticos most(0.3,0.8), at least half(0,0.5), as many as possible(0.5,1).
b = 1.0 # Parámetro de rigurosidad del proceso de consenso. Valores apropiados: 0.5, 0.7, 0.9 y 1.0.
beta = 0.8 # Parámetro para controlar el comportamiento del operador OWA OR-LIKE. Valor en [0,1].

# PROCESO DE CONSENSO
# ====================

w_crit = [1.0] # Solo hay un criterio, por lo tanto peso 1.0.
w_exp = calcular_pesos_OWA(n_exp, ag_lq) # Calculamos los pesos OWA de los expertos mediante los cuantificadores lingüísticos.
w_alt = calcular_pesos_OWA(n_alt, ex_lq) # Calculamos los pesos OWA de las alternativas mediante los cuantificadores lingüísticos.

cm = 0.0 # Inicializamos el consenso del grupo a 0 (disenso total).
c_round = 0 # Ronda actual del proceso de consenso.

while c_round < maxRounds and cm < cl: # El proceso acaba cuando alcanzemos el máximo de rondas permitido o el umbral de consenso
  col = calcular_colectiva_OWA(pref, n_exp, n_alt, n_crit, w_crit, w_exp) # Calculamos la colectiva del grupo agregando con el operador OWA.
  pref[n_exp] = col # Almacenamos la colectiva en la última posición del array de preferencias.

  visualizar_preferencias(pref, "Ronda " + str(c_round), 'MDS') # Esto no tiene nada que ver con el modelo, simplemente es una representación gráfica que ayudar a entender cómo evoluciona el proceso.

  alternatives_rankings = [None] * (n_exp + 1)
  
  for i in range(n_exp + 1):
    QGDD = calcular_QGDD(n_alt, pref[i], w_alt) # Calculamos el quantifier guided dominance degree de las alternativas para cada experto y colectiva.
    alternatives_rankings[i] = np.argsort(QGDD)[::-1] # Obtenemos el ranking de las alternativas en función del valor del QGDD.

  xSol = conjunto_solucion(alternatives_rankings[-1]) # Conjunto solución de la/s mejor/es alternativas según la opinión colectiva.

  differences_rankings = calcular_diferencia_rankings(alternatives_rankings) # Calculamos las diferencias entre los rankings de los expertos y el ranking del grupo.
  consensus_degree_exp_alt = calcular_consenso_exp_alt(differences_rankings, b) # Calculamos el grado de consenso por alternativas para cada experto.
  consensus_degree_alt = calcular_consenso_alt(consensus_degree_exp_alt) # Calculamos el grado de consenso colectivo para cada alternativa.
  cm = s_owa_or_like(consensus_degree_alt, beta, xSol) # Calculamos el grado de consenso colectivo mediante el operador OWA OR-LIKE.

  if cm < cl: # Si no hemos alcanzado el umbral mínimo de consenso hay que recomendar a los expertos que cambien sus preferencias.
    proximity_measures = calcular_medidas_proximidad(consensus_degree_exp_alt, beta, xSol) # Calculamos la proximidad de cada experto a la solución colectiva.
    farthest_experts = expertos_mas_alejados(proximity_measures) # Obtenemos los expertos cuyas opiniones están más alejadas de la opinión del grupo.
    changes = detectar_cambios(farthest_experts, differences_rankings) # Identificamos los cambios a sugerir a los expertos.
    aplicar_cambios(changes, pref) # Aplicamos los cambios a las preferencias de los expertos.

    c_round = c_round + 1
  
  print("Ronda " + str(c_round) + " - Grado de consenso: " + str(cm))
  print("Matriz de preferencias de colectivo:")
  print(pref[-1])
  
  
    
